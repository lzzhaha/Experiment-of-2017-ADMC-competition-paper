{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zlina\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (74,75) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "\n",
    "student_log_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.startswith('student_log')]\n",
    "training_label_path = os.path.join(data_dir, 'training_label.csv')\n",
    "validation_test_label = os.path.join(data_dir, 'validation_test_label.csv')\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for path in student_log_paths:\n",
    "    temp = pd.read_csv(path)\n",
    "    dfs.append(temp)\n",
    "student_df = pd.concat(dfs)\n",
    "\n",
    "training_label_df = pd.read_csv(training_label_path)\n",
    "validation_test_label_df = pd.read_csv(validation_test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student_df = student_df.drop_duplicates(['ITEST_id'])\n",
    "#training_label_df = training_label_df.drop_duplicates(['ITEST_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_df.shape: (942816, 77)\n",
      "training_label_df.shape: (514, 5)\n",
      "validation_test_label_df.shape: (172, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"student_df.shape:\", student_df.shape) \n",
    "print(\"training_label_df.shape:\", training_label_df.shape)\n",
    "print(\"validation_test_label_df.shape:\", validation_test_label_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skill = student_df.skill.unique()\n",
    "skill_id = range(len(skill))\n",
    "skill_id_map = dict(zip(skill, skill_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31906614785992216\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(training_label_df['isSTEM']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "student_specific_columns = [\"AveKnow\",\n",
    "                            \"AveCarelessness\",\n",
    "                            \"AveCorrect\",\n",
    "                            \"NumActions\",\n",
    "                            \"AveResBored\",\n",
    "                            \"AveResEngcon\",\n",
    "                            \"AveResConf\",\n",
    "                            \"AveResFrust\",\n",
    "                            \"AveResOfftask\",\n",
    "                            \"AveResGaming\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "required_cols = ['ITEST_id'] + student_specific_columns\n",
    "student_specific_df = student_df[required_cols].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combined_df = pd.merge(left=training_label_df, right=student_specific_df, how='left', left_on='ITEST_id', right_on='ITEST_id')\n",
    "combined_df_train = training_label_df.merge(student_specific_df, left_on='ITEST_id', right_on='ITEST_id', how='left')\n",
    "combined_df_train['AveCorrect'] = combined_df_train['AveCorrect_x']\n",
    "del combined_df_train['AveCorrect_x']\n",
    "del combined_df_train['AveCorrect_y']\n",
    "X_static = combined_df_train[student_specific_columns].values\n",
    "y_static = combined_df_train['isSTEM'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_df_test = pd.merge(left=validation_test_label_df, right=student_specific_df, how='left')\n",
    "X_target = combined_df_test[student_specific_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEST_id</th>\n",
       "      <th>SchoolId</th>\n",
       "      <th>MCAS</th>\n",
       "      <th>isSTEM</th>\n",
       "      <th>AveKnow</th>\n",
       "      <th>AveCarelessness</th>\n",
       "      <th>NumActions</th>\n",
       "      <th>AveResBored</th>\n",
       "      <th>AveResEngcon</th>\n",
       "      <th>AveResConf</th>\n",
       "      <th>AveResFrust</th>\n",
       "      <th>AveResOfftask</th>\n",
       "      <th>AveResGaming</th>\n",
       "      <th>AveCorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.185138</td>\n",
       "      <td>0.099734</td>\n",
       "      <td>504</td>\n",
       "      <td>0.277149</td>\n",
       "      <td>0.644744</td>\n",
       "      <td>0.098078</td>\n",
       "      <td>0.162771</td>\n",
       "      <td>0.213378</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>0.438492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142031</td>\n",
       "      <td>0.069297</td>\n",
       "      <td>129</td>\n",
       "      <td>0.330226</td>\n",
       "      <td>0.551367</td>\n",
       "      <td>0.122658</td>\n",
       "      <td>0.095420</td>\n",
       "      <td>0.348090</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.348837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.459813</td>\n",
       "      <td>0.202787</td>\n",
       "      <td>169</td>\n",
       "      <td>0.260426</td>\n",
       "      <td>0.650769</td>\n",
       "      <td>0.059971</td>\n",
       "      <td>0.061834</td>\n",
       "      <td>0.296286</td>\n",
       "      <td>0.010954</td>\n",
       "      <td>0.686391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.255164</td>\n",
       "      <td>0.158848</td>\n",
       "      <td>993</td>\n",
       "      <td>0.222796</td>\n",
       "      <td>0.650079</td>\n",
       "      <td>0.069987</td>\n",
       "      <td>0.164347</td>\n",
       "      <td>0.153147</td>\n",
       "      <td>0.236800</td>\n",
       "      <td>0.379658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>-999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071909</td>\n",
       "      <td>0.046183</td>\n",
       "      <td>121</td>\n",
       "      <td>0.326384</td>\n",
       "      <td>0.653445</td>\n",
       "      <td>0.125325</td>\n",
       "      <td>0.094714</td>\n",
       "      <td>0.451467</td>\n",
       "      <td>0.016241</td>\n",
       "      <td>0.305785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ITEST_id  SchoolId  MCAS  isSTEM   AveKnow  AveCarelessness  NumActions  \\\n",
       "0         9         2    32       1  0.185138         0.099734         504   \n",
       "1        27         1    21       0  0.142031         0.069297         129   \n",
       "2        33         2    52       0  0.459813         0.202787         169   \n",
       "3        35         2    34       0  0.255164         0.158848         993   \n",
       "4        37         3  -999       0  0.071909         0.046183         121   \n",
       "\n",
       "   AveResBored  AveResEngcon  AveResConf  AveResFrust  AveResOfftask  \\\n",
       "0     0.277149      0.644744    0.098078     0.162771       0.213378   \n",
       "1     0.330226      0.551367    0.122658     0.095420       0.348090   \n",
       "2     0.260426      0.650769    0.059971     0.061834       0.296286   \n",
       "3     0.222796      0.650079    0.069987     0.164347       0.153147   \n",
       "4     0.326384      0.653445    0.125325     0.094714       0.451467   \n",
       "\n",
       "   AveResGaming  AveCorrect  \n",
       "0      0.005554    0.438492  \n",
       "1      0.036900    0.348837  \n",
       "2      0.010954    0.686391  \n",
       "3      0.236800    0.379658  \n",
       "4      0.016241    0.305785  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model of DKT\n",
    "If you want to change the model with different regularization parameters\n",
    "Simply change\n",
    "```python\n",
    "network_config['lambda_o']\n",
    "network_config['lambda_w1']\n",
    "network_config['lambda_w2']\n",
    "```\n",
    "to the desired value\n",
    "\n",
    "---\n",
    "To use the original DKT model without any regularization:\n",
    "```python\n",
    "network_config['lambda_o'] = 0.0\n",
    "network_config['lambda_w1'] = 0.0\n",
    "network_config['lambda_w2'] = 0.0\n",
    "```\n",
    "\n",
    "To use the original DKT model with regularization:\n",
    "```python\n",
    "network_config['lambda_o'] = 0.1\n",
    "network_config['lambda_w1'] = 0.3\n",
    "network_config['lambda_w2'] = 3.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain student's DKT feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DKT feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "students_dk_df = pd.read_csv('./data/students_knowledge_states_dkt.csv')\n",
    "combined_df = pd.merge(left=student_specific_df, right=students_dk_df, how='left')\n",
    "train_df = training_label_df.merge(combined_df, left_on='ITEST_id', right_on='ITEST_id', how='left')\n",
    "test_df = validation_test_label_df.merge(combined_df, left_on='ITEST_id', right_on='ITEST_id', how='left')\n",
    "train_df['AveCorrect'] = train_df['AveCorrect_x']\n",
    "del train_df['AveCorrect_x']\n",
    "del train_df['AveCorrect_y']\n",
    "test_df['AveCorrect'] = test_df['AveCorrect_x']\n",
    "del test_df['AveCorrect_x']\n",
    "del test_df['AveCorrect_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_cols = list(train_df.columns.drop(['ITEST_id', 'isSTEM', 'SchoolId', 'MCAS']))\n",
    "X_dkt = train_df[features_cols].values\n",
    "y_dkt = train_df['isSTEM'].values\n",
    "#X_test_dkt = test_df[features_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveKnow</th>\n",
       "      <th>AveCarelessness</th>\n",
       "      <th>NumActions</th>\n",
       "      <th>AveResBored</th>\n",
       "      <th>AveResEngcon</th>\n",
       "      <th>AveResConf</th>\n",
       "      <th>AveResFrust</th>\n",
       "      <th>AveResOfftask</th>\n",
       "      <th>AveResGaming</th>\n",
       "      <th>kt_0</th>\n",
       "      <th>...</th>\n",
       "      <th>kt_91</th>\n",
       "      <th>kt_92</th>\n",
       "      <th>kt_93</th>\n",
       "      <th>kt_94</th>\n",
       "      <th>kt_95</th>\n",
       "      <th>kt_96</th>\n",
       "      <th>kt_97</th>\n",
       "      <th>kt_98</th>\n",
       "      <th>kt_99</th>\n",
       "      <th>AveCorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.185138</td>\n",
       "      <td>0.099734</td>\n",
       "      <td>504</td>\n",
       "      <td>0.277149</td>\n",
       "      <td>0.644744</td>\n",
       "      <td>0.098078</td>\n",
       "      <td>0.162771</td>\n",
       "      <td>0.213378</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>0.056223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604331</td>\n",
       "      <td>0.811209</td>\n",
       "      <td>0.816579</td>\n",
       "      <td>0.727060</td>\n",
       "      <td>0.834404</td>\n",
       "      <td>0.784057</td>\n",
       "      <td>0.698990</td>\n",
       "      <td>0.686475</td>\n",
       "      <td>0.825749</td>\n",
       "      <td>0.438492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.142031</td>\n",
       "      <td>0.069297</td>\n",
       "      <td>129</td>\n",
       "      <td>0.330226</td>\n",
       "      <td>0.551367</td>\n",
       "      <td>0.122658</td>\n",
       "      <td>0.095420</td>\n",
       "      <td>0.348090</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.078004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588781</td>\n",
       "      <td>0.685849</td>\n",
       "      <td>0.668140</td>\n",
       "      <td>0.613515</td>\n",
       "      <td>0.578640</td>\n",
       "      <td>0.679307</td>\n",
       "      <td>0.593397</td>\n",
       "      <td>0.615776</td>\n",
       "      <td>0.589999</td>\n",
       "      <td>0.348837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.459813</td>\n",
       "      <td>0.202787</td>\n",
       "      <td>169</td>\n",
       "      <td>0.260426</td>\n",
       "      <td>0.650769</td>\n",
       "      <td>0.059971</td>\n",
       "      <td>0.061834</td>\n",
       "      <td>0.296286</td>\n",
       "      <td>0.010954</td>\n",
       "      <td>0.032441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562058</td>\n",
       "      <td>0.647350</td>\n",
       "      <td>0.886021</td>\n",
       "      <td>0.810916</td>\n",
       "      <td>0.849762</td>\n",
       "      <td>0.765824</td>\n",
       "      <td>0.713093</td>\n",
       "      <td>0.765192</td>\n",
       "      <td>0.872928</td>\n",
       "      <td>0.686391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.255164</td>\n",
       "      <td>0.158848</td>\n",
       "      <td>993</td>\n",
       "      <td>0.222796</td>\n",
       "      <td>0.650079</td>\n",
       "      <td>0.069987</td>\n",
       "      <td>0.164347</td>\n",
       "      <td>0.153147</td>\n",
       "      <td>0.236800</td>\n",
       "      <td>0.032341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565016</td>\n",
       "      <td>0.586461</td>\n",
       "      <td>0.676752</td>\n",
       "      <td>0.629468</td>\n",
       "      <td>0.601491</td>\n",
       "      <td>0.670198</td>\n",
       "      <td>0.592042</td>\n",
       "      <td>0.556765</td>\n",
       "      <td>0.653874</td>\n",
       "      <td>0.379658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.071909</td>\n",
       "      <td>0.046183</td>\n",
       "      <td>121</td>\n",
       "      <td>0.326384</td>\n",
       "      <td>0.653445</td>\n",
       "      <td>0.125325</td>\n",
       "      <td>0.094714</td>\n",
       "      <td>0.451467</td>\n",
       "      <td>0.016241</td>\n",
       "      <td>0.073857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433965</td>\n",
       "      <td>0.515282</td>\n",
       "      <td>0.592892</td>\n",
       "      <td>0.605307</td>\n",
       "      <td>0.456578</td>\n",
       "      <td>0.573977</td>\n",
       "      <td>0.553958</td>\n",
       "      <td>0.523287</td>\n",
       "      <td>0.539461</td>\n",
       "      <td>0.305785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AveKnow  AveCarelessness  NumActions  AveResBored  AveResEngcon  \\\n",
       "0  0.185138         0.099734         504     0.277149      0.644744   \n",
       "1  0.142031         0.069297         129     0.330226      0.551367   \n",
       "2  0.459813         0.202787         169     0.260426      0.650769   \n",
       "3  0.255164         0.158848         993     0.222796      0.650079   \n",
       "4  0.071909         0.046183         121     0.326384      0.653445   \n",
       "\n",
       "   AveResConf  AveResFrust  AveResOfftask  AveResGaming      kt_0     ...      \\\n",
       "0    0.098078     0.162771       0.213378      0.005554  0.056223     ...       \n",
       "1    0.122658     0.095420       0.348090      0.036900  0.078004     ...       \n",
       "2    0.059971     0.061834       0.296286      0.010954  0.032441     ...       \n",
       "3    0.069987     0.164347       0.153147      0.236800  0.032341     ...       \n",
       "4    0.125325     0.094714       0.451467      0.016241  0.073857     ...       \n",
       "\n",
       "      kt_91     kt_92     kt_93     kt_94     kt_95     kt_96     kt_97  \\\n",
       "0  0.604331  0.811209  0.816579  0.727060  0.834404  0.784057  0.698990   \n",
       "1  0.588781  0.685849  0.668140  0.613515  0.578640  0.679307  0.593397   \n",
       "2  0.562058  0.647350  0.886021  0.810916  0.849762  0.765824  0.713093   \n",
       "3  0.565016  0.586461  0.676752  0.629468  0.601491  0.670198  0.592042   \n",
       "4  0.433965  0.515282  0.592892  0.605307  0.456578  0.573977  0.553958   \n",
       "\n",
       "      kt_98     kt_99  AveCorrect  \n",
       "0  0.686475  0.825749    0.438492  \n",
       "1  0.615776  0.589999    0.348837  \n",
       "2  0.765192  0.872928    0.686391  \n",
       "3  0.556765  0.653874    0.379658  \n",
       "4  0.523287  0.539461    0.305785  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[features_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DKT+ feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "students_dk_df = pd.read_csv('./data/students_knowledge_states_dktp.csv')\n",
    "combined_df = pd.merge(left=student_specific_df, right=students_dk_df, how='left')\n",
    "train_df = training_label_df.merge(combined_df, left_on='ITEST_id', right_on='ITEST_id', how='left')\n",
    "#test_df = validation_test_label_df.merge(combined_df, left_on='ITEST_id', right_on='ITEST_id', how='left')\n",
    "train_df['AveCorrect'] = train_df['AveCorrect_x']\n",
    "del train_df['AveCorrect_x']\n",
    "del train_df['AveCorrect_y']\n",
    "#test_df['AveCorrect'] = test_df['AveCorrect_x']\n",
    "#del test_df['AveCorrect_x']\n",
    "#del test_df['AveCorrect_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_cols = list(train_df.columns.drop(['ITEST_id', 'isSTEM', 'SchoolId', 'MCAS']))\n",
    "X_dktp = train_df[features_cols].values\n",
    "y_dktp = train_df['isSTEM'].values\n",
    "#X_test_dktp = test_df[features_cols].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the static machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (auc, roc_curve, mean_squared_error, make_scorer, accuracy_score, precision_score, recall_score,\n",
    "average_precision_score, f1_score)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_param_grid = {\n",
    "    'penalty': ['l1', 'l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_param_grid = {\n",
    "    'C': [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0, 10.0, 30.0, 100.0], \n",
    "    'gamma': [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0, 10.0, 30.0, 100.0], \n",
    "    'kernel': ['rbf']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbdt_param_grid = {\n",
    "    'n_estimators': [200, 250, 300, 350, 400, 450, 500, 550], \n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5, 6, 7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "mlp_layer_search_list = list(itertools.product([16, 64, 128, 256]))\n",
    "mlp_layer_search_list += list(itertools.product([16, 64, 128, 256], [16, 64, 128, 256]))\n",
    "mlp_layer_search_list += list(itertools.product([16, 64, 128, 256], [16, 64, 128, 256], [16, 64, 128, 256]))\n",
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': mlp_layer_search_list,\n",
    "    'early_stopping': [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_param_grid = {'solver':['svd', 'lsqr', 'eigen'], 'tol':[1e-10, 3e-10, 1e-9, 3e-9, 1e-8, 3e-8] }\n",
    "\n",
    "qda_param_grid = {'tol':[1e-10, 3e-10, 1e-9, 3e-9, 1e-8, 3e-8]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define customized scorer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auc_score(y_true, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred, pos_label=1)\n",
    "    auc_ = auc(fpr, tpr)\n",
    "    return auc_\n",
    "auc_scorer = make_scorer(auc_score, greater_is_better = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse_score(y_true, y_pred):\n",
    "    rmse_ = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    return rmse_\n",
    "rmse_scorer = make_scorer(rmse_score, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation metric of ASSISTments DM Competition\n",
    "def admc_score(y_true, y_pred):\n",
    "    # auc\n",
    "    auc_ = auc_score(y_true, y_pred)\n",
    "    \n",
    "    # rmse\n",
    "    rmse_ = rmse_score(y_true, y_pred)\n",
    "    \n",
    "    \n",
    "    return auc_ + (1 - rmse_)\n",
    "\n",
    "admc_scorer = make_scorer(admc_score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithm_dict = {'LR': LogisticRegression(), 'SVM': SVC(), 'ANN':MLPClassifier(), 'GBDT': GradientBoostingClassifier(), \n",
    "                 'LDA': LinearDiscriminantAnalysis(), 'QDA': QuadraticDiscriminantAnalysis() }\n",
    "\n",
    "#algorithm_dict = {'LDA': LinearDiscriminantAnalysis(), 'QDA': QuadraticDiscriminantAnalysis()}\n",
    "feature_list = ['static', 'DKT', 'DKT+']\n",
    "param_dict = {'LR': lr_param_grid, 'SVM': svm_param_grid, 'ANN': mlp_param_grid, 'GBDT': gbdt_param_grid,\n",
    "              'LDA': lda_param_grid, 'QDA': qda_param_grid}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define cross-validation for multiple metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "cross validate the input estimator using stratified  n_fold shuffle split,\n",
    "return the mean and std of each metric in dictionary format\n",
    "\n",
    "params:\n",
    "scoring_dict : with metric name (e.g. 'AUC') as keys and \n",
    "callable scoring function as values, which has the signature\n",
    "of (y_true, y_pred) and return scores\n",
    "\n",
    "return:\n",
    "score_dict: with metric name (e.g. 'AUC') as keys and \n",
    "mean +/- 2*std string as values\n",
    "'''\n",
    "\n",
    "def multi_metrics_cv(estimator, X, y, scoring_method_dict, n_fold = 10):\n",
    "    sss = StratifiedShuffleSplit(n_splits=5, random_state=42)\n",
    "    \n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        X_train, y_train = X[train_index], y[train_index]\n",
    "        X_test, y_test = X[test_index], y[test_index]\n",
    "        \n",
    "        ros = RandomOverSampler(random_state=42)\n",
    "        X_train, y_train = ros.fit_sample(X_train, y_train)\n",
    "        estimator.fit(X_train, y_train)\n",
    "        \n",
    "        \n",
    "        y_pred = estimator.predict(X_test)\n",
    "        \n",
    "        score_list_dict =  {'AUC': [], \n",
    "                'RMSE': [], \n",
    "                'AUC + (1-RMSE)':[], \n",
    "                'Accuracy':[], \n",
    "                'Precision':[], \n",
    "                'Recall': [] ,\n",
    "                'F1':[],\n",
    "                'AP': []}\n",
    "        score_dict = {}\n",
    "        \n",
    "        for metric in scoring_method_dict:\n",
    "            \n",
    "            score = scoring_method_dict[metric](y_test, y_pred)\n",
    "            \n",
    "            score_list_dict[metric].append(score)\n",
    "    \n",
    "    for metric in scoring_method_dict:\n",
    "        mean = np.mean(score_list_dict[metric])\n",
    "        std = np.std(score_list_dict[metric])\n",
    "        val_str = \"{:.3f} $\\pm$ {:.3f}\".format(mean, std)\n",
    "        score_dict[metric] = val_str\n",
    "        \n",
    "\n",
    "    return score_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform test on each clf with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get experimental result of each clf on feature\n",
    "#repeate 5 times and store the average +- 2*std\n",
    "#e.g. score_dict['AUC'] = ['0.9 +- 0.01']\n",
    "def eval_model2(clf, X, y):\n",
    "    \n",
    "    #A dictionary containing the name string or callable of scoring  methods \n",
    "    scoring_method_dict = {\n",
    "        'AUC': auc_score,\n",
    "        'RMSE': rmse_score, \n",
    "        'AUC + (1-RMSE)': admc_score,\n",
    "        'Accuracy': accuracy_score, \n",
    "        'Precision': precision_score, \n",
    "        'Recall': recall_score, \n",
    "        'AP': precision_score, \n",
    "        'F1': f1_score\n",
    "    }\n",
    "    \n",
    "    # finding the best parameters\n",
    "    clf.fit(X,y)\n",
    "   \n",
    "\n",
    "    \n",
    "    # get the best estimator\n",
    "    estimator = clf.best_estimator_\n",
    "\n",
    "    score_dict = multi_metrics_cv(estimator = estimator, X=X, y=y, scoring_method_dict = scoring_method_dict, n_fold=5)\n",
    "    \n",
    "    return score_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Perform parameter search and test on each feature set on 4 clfs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do parameter search and get experimental result on given feature (string)\n",
    "#return a dictionary containing the scores of each clf\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "def test_feature2(feature):\n",
    "    \n",
    "    cv = StratifiedShuffleSplit(n_splits=5, random_state=42)\n",
    "    \n",
    "    res_dict = {'name': [], \n",
    "                'AUC': [], \n",
    "                'RMSE': [], \n",
    "                'Accuracy':[], \n",
    "                'AUC + (1-RMSE)':[], \n",
    "                'Precision':[], \n",
    "                'Recall': [] ,\n",
    "                'AP': [], \n",
    "                'F1':[]}\n",
    "    best_param_dict = {'name': [], 'params': []}\n",
    "    \n",
    "    \n",
    "    if feature == 'static':\n",
    "        X_train = X_static\n",
    "        y_train = y_static\n",
    "        \n",
    "    elif feature == 'DKT':\n",
    "        X_train = X_dkt\n",
    "        y_train = y_dkt\n",
    "        \n",
    "        \n",
    "    elif feature == 'DKT+':\n",
    "        X_train = X_dktp\n",
    "        y_train = y_dktp\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print('Please select correct feature!')\n",
    "        return \n",
    "    \n",
    "    \n",
    "    for algorithm in algorithm_dict:\n",
    "        print(algorithm)\n",
    "        \n",
    "        #Parameter search\n",
    "        clf = GridSearchCV(estimator=algorithm_dict[algorithm],\n",
    "                  param_grid=param_dict[algorithm],\n",
    "                  scoring=admc_scorer,\n",
    "                  refit = True,\n",
    "                  cv=cv,\n",
    "                  verbose=1,\n",
    "                  return_train_score=True)\n",
    "        \n",
    "        \n",
    "        #estimator = clf.best_estimator_\n",
    "        \n",
    "        score_dict = eval_model2(clf=clf, X=X_train, y=y_train)\n",
    "        \n",
    "        #Append the score into dictionaries\n",
    "        res_dict['name'].append(algorithm)\n",
    "        best_param_dict['name'].append(algorithm)\n",
    "        best_param_dict['params'].append(clf.best_params_)\n",
    "        \n",
    "        \n",
    "        for score in score_dict:\n",
    "            res_dict[score].append(score_dict[score])\n",
    "    \n",
    "    return res_dict, best_param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write result tabel of approach 2 to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "SVM\n",
      "Fitting 5 folds for each of 121 candidates, totalling 605 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 605 out of 605 | elapsed:   15.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN\n",
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 420 out of 420 | elapsed:   11.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 960 out of 960 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "QDA\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "static result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>AP</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUC + (1-RMSE)</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.500 $\\pm$ 0.000</td>\n",
       "      <td>0.606 $\\pm$ 0.000</td>\n",
       "      <td>1.034 $\\pm$ 0.000</td>\n",
       "      <td>0.673 $\\pm$ 0.000</td>\n",
       "      <td>0.452 $\\pm$ 0.000</td>\n",
       "      <td>0.500 $\\pm$ 0.000</td>\n",
       "      <td>0.572 $\\pm$ 0.000</td>\n",
       "      <td>0.412 $\\pm$ 0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.923 $\\pm$ 0.000</td>\n",
       "      <td>0.839 $\\pm$ 0.000</td>\n",
       "      <td>1.499 $\\pm$ 0.000</td>\n",
       "      <td>0.885 $\\pm$ 0.000</td>\n",
       "      <td>0.800 $\\pm$ 0.000</td>\n",
       "      <td>0.923 $\\pm$ 0.000</td>\n",
       "      <td>0.340 $\\pm$ 0.000</td>\n",
       "      <td>0.706 $\\pm$ 0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANN</td>\n",
       "      <td>0.327 $\\pm$ 0.000</td>\n",
       "      <td>0.500 $\\pm$ 0.000</td>\n",
       "      <td>0.680 $\\pm$ 0.000</td>\n",
       "      <td>0.327 $\\pm$ 0.000</td>\n",
       "      <td>0.493 $\\pm$ 0.000</td>\n",
       "      <td>0.327 $\\pm$ 0.000</td>\n",
       "      <td>0.820 $\\pm$ 0.000</td>\n",
       "      <td>1.000 $\\pm$ 0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>0.750 $\\pm$ 0.000</td>\n",
       "      <td>0.796 $\\pm$ 0.000</td>\n",
       "      <td>1.380 $\\pm$ 0.000</td>\n",
       "      <td>0.827 $\\pm$ 0.000</td>\n",
       "      <td>0.727 $\\pm$ 0.000</td>\n",
       "      <td>0.750 $\\pm$ 0.000</td>\n",
       "      <td>0.416 $\\pm$ 0.000</td>\n",
       "      <td>0.706 $\\pm$ 0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.421 $\\pm$ 0.000</td>\n",
       "      <td>0.578 $\\pm$ 0.000</td>\n",
       "      <td>0.958 $\\pm$ 0.000</td>\n",
       "      <td>0.615 $\\pm$ 0.000</td>\n",
       "      <td>0.444 $\\pm$ 0.000</td>\n",
       "      <td>0.421 $\\pm$ 0.000</td>\n",
       "      <td>0.620 $\\pm$ 0.000</td>\n",
       "      <td>0.471 $\\pm$ 0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.458 $\\pm$ 0.000</td>\n",
       "      <td>0.638 $\\pm$ 0.000</td>\n",
       "      <td>1.033 $\\pm$ 0.000</td>\n",
       "      <td>0.635 $\\pm$ 0.000</td>\n",
       "      <td>0.537 $\\pm$ 0.000</td>\n",
       "      <td>0.458 $\\pm$ 0.000</td>\n",
       "      <td>0.604 $\\pm$ 0.000</td>\n",
       "      <td>0.647 $\\pm$ 0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name                 AP                AUC     AUC + (1-RMSE)  \\\n",
       "0    LR  0.500 $\\pm$ 0.000  0.606 $\\pm$ 0.000  1.034 $\\pm$ 0.000   \n",
       "1   SVM  0.923 $\\pm$ 0.000  0.839 $\\pm$ 0.000  1.499 $\\pm$ 0.000   \n",
       "2   ANN  0.327 $\\pm$ 0.000  0.500 $\\pm$ 0.000  0.680 $\\pm$ 0.000   \n",
       "3  GBDT  0.750 $\\pm$ 0.000  0.796 $\\pm$ 0.000  1.380 $\\pm$ 0.000   \n",
       "4   LDA  0.421 $\\pm$ 0.000  0.578 $\\pm$ 0.000  0.958 $\\pm$ 0.000   \n",
       "5   QDA  0.458 $\\pm$ 0.000  0.638 $\\pm$ 0.000  1.033 $\\pm$ 0.000   \n",
       "\n",
       "            Accuracy                 F1          Precision               RMSE  \\\n",
       "0  0.673 $\\pm$ 0.000  0.452 $\\pm$ 0.000  0.500 $\\pm$ 0.000  0.572 $\\pm$ 0.000   \n",
       "1  0.885 $\\pm$ 0.000  0.800 $\\pm$ 0.000  0.923 $\\pm$ 0.000  0.340 $\\pm$ 0.000   \n",
       "2  0.327 $\\pm$ 0.000  0.493 $\\pm$ 0.000  0.327 $\\pm$ 0.000  0.820 $\\pm$ 0.000   \n",
       "3  0.827 $\\pm$ 0.000  0.727 $\\pm$ 0.000  0.750 $\\pm$ 0.000  0.416 $\\pm$ 0.000   \n",
       "4  0.615 $\\pm$ 0.000  0.444 $\\pm$ 0.000  0.421 $\\pm$ 0.000  0.620 $\\pm$ 0.000   \n",
       "5  0.635 $\\pm$ 0.000  0.537 $\\pm$ 0.000  0.458 $\\pm$ 0.000  0.604 $\\pm$ 0.000   \n",
       "\n",
       "              Recall  \n",
       "0  0.412 $\\pm$ 0.000  \n",
       "1  0.706 $\\pm$ 0.000  \n",
       "2  1.000 $\\pm$ 0.000  \n",
       "3  0.706 $\\pm$ 0.000  \n",
       "4  0.471 $\\pm$ 0.000  \n",
       "5  0.647 $\\pm$ 0.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "static best_params\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 3.0, 'gamma': 30.0, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANN</td>\n",
       "      <td>{'early_stopping': True, 'hidden_layer_sizes':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 4, 'n_est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDA</td>\n",
       "      <td>{'solver': 'lsqr', 'tol': 1e-10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QDA</td>\n",
       "      <td>{'tol': 1e-10}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name                                             params\n",
       "0    LR                                  {'penalty': 'l1'}\n",
       "1   SVM         {'C': 3.0, 'gamma': 30.0, 'kernel': 'rbf'}\n",
       "2   ANN  {'early_stopping': True, 'hidden_layer_sizes':...\n",
       "3  GBDT  {'max_depth': 4, 'min_samples_leaf': 4, 'n_est...\n",
       "4   LDA                   {'solver': 'lsqr', 'tol': 1e-10}\n",
       "5   QDA                                     {'tol': 1e-10}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Fitting 5 folds for each of 121 candidates, totalling 605 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 605 out of 605 | elapsed:   53.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN\n",
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 420 out of 420 | elapsed:   15.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "for feature in feature_list:\n",
    "    \n",
    "    res_dict, best_param_dict = test_feature2(feature)\n",
    "    \n",
    "    #Convert the model name according to the features used (Optional)\n",
    "    suffix = ('' if feature=='static' else ('-' + feature))\n",
    "    \n",
    "    \n",
    "    for i in range(0,  len(res_dict['name']), 1):\n",
    "        new_name = res_dict['name'][i] + suffix\n",
    "        res_dict['name'][i] = new_name\n",
    "        best_param_dict['name'][i] = new_name\n",
    "    ####################################################\n",
    "    \n",
    "   \n",
    "    \n",
    "    res_df = pd.DataFrame(data = res_dict)\n",
    "    \n",
    "    print('{:s} result'.format(feature))\n",
    "    col = list(res_df.columns)\n",
    "    col = [col[-1]] + col[:-1]\n",
    "    res_df = res_df[col]\n",
    "    \n",
    "    display(res_df)\n",
    "    \n",
    "    res_df.to_csv('./experiment/{:s}_score_2.csv'.format(feature), index=False, header=True)\n",
    "    \n",
    "    best_param_df = pd.DataFrame(data = best_param_dict)\n",
    "    \n",
    "    print('{:s} best_params'.format(feature))\n",
    "    display(best_param_df)\n",
    "         \n",
    "    best_param_df.to_csv('./experiment/{:s}_best_params_2.csv'.format(feature, index=False, header=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
